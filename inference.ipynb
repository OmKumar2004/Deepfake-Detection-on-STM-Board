{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3654a4e",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '3.13.2 (Python 3.13.2)' requires the ipykernel package.\n",
      "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages.\n",
      "\u001b[1;31mOr install 'ipykernel' using the command: 'c:/Users/omkum/.pyenv/pyenv-win/versions/3.13.2/python.exe -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import sys\n",
    "\n",
    "# Load the TFLite model\n",
    "interpreter = tf.lite.Interpreter(model_path=\"student_model_tiny.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output tensors info\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# Function to preprocess the input image\n",
    "def preprocess_image(image_path):\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image = image.resize((64, 64))\n",
    "    image = np.asarray(image).astype(np.float32) / 255.0\n",
    "\n",
    "    # Normalize using the same mean and std used during training\n",
    "    mean = np.array([0.485, 0.456, 0.406], dtype=np.float32)\n",
    "    std = np.array([0.229, 0.224, 0.225], dtype=np.float32)\n",
    "    image = (image - mean) / std\n",
    "\n",
    "    # Convert HWC -> CHW\n",
    "    image = image.transpose(2, 0, 1)\n",
    "\n",
    "    # Add batch dimension\n",
    "    image = np.expand_dims(image, axis=0).astype(np.float32)\n",
    "    return image\n",
    "\n",
    "\n",
    "for i in range(12):\n",
    "    # Load and preprocess input imag\n",
    "    image_path = f\"./images/image_{i}.png\"\n",
    "    input_data = preprocess_image(image_path)\n",
    "\n",
    "    # Ensure input type matches the model's expected type\n",
    "    input_index = input_details[0]['index']\n",
    "    interpreter.set_tensor(input_index, input_data)\n",
    "\n",
    "    # Run inference\n",
    "    interpreter.invoke()\n",
    "\n",
    "    # Get the output\n",
    "    output_index = output_details[0]['index']\n",
    "    output_data = interpreter.get_tensor(output_index)\n",
    "\n",
    "    # Get predicted class\n",
    "    predicted_class = np.argmax(output_data)\n",
    "    print(f\"Predicted class: {predicted_class}, Scores: {output_data}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70708912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input details: [{'name': 'serving_default_input:0', 'index': 0, 'shape': array([ 1,  3, 64, 64], dtype=int32), 'shape_signature': array([ 1,  3, 64, 64], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n",
      "Expected input shape: [ 1  3 64 64]\n",
      "Expected input type: <class 'numpy.float32'>\n",
      "Image 0: Predicted class: 0, Confidence: -6.0072  Full scores: [-6.0072184 -7.4837065]\n",
      "Image 1: Predicted class: 0, Confidence: -8.3040  Full scores: [ -8.303981 -10.891712]\n",
      "Image 2: Predicted class: 1, Confidence: -4.0905  Full scores: [-6.4334745 -4.0905094]\n",
      "Image 3: Predicted class: 0, Confidence: -6.0769  Full scores: [-6.0769405 -7.6767435]\n",
      "Image 4: Predicted class: 1, Confidence: 0.4733  Full scores: [-9.711008    0.47329766]\n",
      "Image 5: Predicted class: 1, Confidence: -3.4028  Full scores: [-8.992496 -3.402752]\n",
      "Image 6: Predicted class: 1, Confidence: -3.4053  Full scores: [-6.548455  -3.4052598]\n",
      "Image 7: Predicted class: 0, Confidence: -3.4390  Full scores: [-3.4389932 -3.5573804]\n",
      "Image 8: Predicted class: 1, Confidence: -3.0812  Full scores: [-10.745894  -3.08122 ]\n",
      "Image 9: Predicted class: 0, Confidence: -6.3409  Full scores: [-6.340886  -6.5217056]\n",
      "Image 10: Predicted class: 1, Confidence: -2.0886  Full scores: [-8.521756  -2.0885513]\n",
      "Image 11: Predicted class: 1, Confidence: -5.9636  Full scores: [-10.206355   -5.9636345]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Load the TFLite model\n",
    "interpreter = tf.lite.Interpreter(model_path=\"student_model_tiny.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output tensors info\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# Print model input details for debugging\n",
    "print(f\"Input details: {input_details}\")\n",
    "print(f\"Expected input shape: {input_details[0]['shape']}\")\n",
    "print(f\"Expected input type: {input_details[0]['dtype']}\")\n",
    "\n",
    "# Function to preprocess the input image\n",
    "def preprocess_image(image_path):\n",
    "    if not os.path.exists(image_path):\n",
    "        print(f\"Error: Image {image_path} not found\")\n",
    "        return None\n",
    "        \n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image = image.resize((64, 64))\n",
    "    image = np.asarray(image).astype(np.float32) / 255.0\n",
    "\n",
    "    # Normalize using the same mean and std used during training\n",
    "    mean = np.array([0.485, 0.456, 0.406], dtype=np.float32)\n",
    "    std = np.array([0.229, 0.224, 0.225], dtype=np.float32)\n",
    "    \n",
    "    # Apply normalization correctly\n",
    "    image = (image - mean) / std\n",
    "\n",
    "    # Convert HWC -> CHW (PyTorch format)\n",
    "    image = image.transpose(2, 0, 1)\n",
    "    \n",
    "    # Add batch dimension\n",
    "    image = np.expand_dims(image, axis=0).astype(np.float32)\n",
    "    \n",
    "    # Check if we need to convert back to HWC for TFLite\n",
    "    if input_details[0]['shape'][3] == 3:  # If the last dimension is 3 (channels)\n",
    "        # Convert back to HWC for TFLite\n",
    "        image = image.transpose(0, 2, 3, 1)\n",
    "        \n",
    "    return image\n",
    "\n",
    "for i in range(12):\n",
    "    # Load and preprocess input image\n",
    "    image_path = f\"./images/image_{i}.png\"\n",
    "    input_data = preprocess_image(image_path)\n",
    "    \n",
    "    if input_data is None:\n",
    "        continue\n",
    "\n",
    "    # Ensure input type matches the model's expected type\n",
    "    input_index = input_details[0]['index']\n",
    "    \n",
    "    # Check if we need to quantize the input\n",
    "    if input_details[0]['dtype'] != np.float32:\n",
    "        print(f\"Converting input to {input_details[0]['dtype']}\")\n",
    "        input_data = input_data.astype(input_details[0]['dtype'])\n",
    "    \n",
    "    interpreter.set_tensor(input_index, input_data)\n",
    "\n",
    "    # Run inference\n",
    "    interpreter.invoke()\n",
    "\n",
    "    # Get the output\n",
    "    output_index = output_details[0]['index']\n",
    "    output_data = interpreter.get_tensor(output_index)\n",
    "\n",
    "    # Get predicted class\n",
    "    predicted_class = np.argmax(output_data)\n",
    "    confidence = output_data[0][predicted_class]\n",
    "    print(f\"Image {i}: Predicted class: {predicted_class}, Confidence: {confidence:.4f}  Full scores: {output_data[0]}\")\n",
    "    # print(f\"Full scores: {output_data[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695d914e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a64aaf7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7b979d0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: 1, Scores: [[-6.688732 -5.56662 ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import sys\n",
    "\n",
    "# Load the TFLite model\n",
    "interpreter = tf.lite.Interpreter(model_path=\"student_model_tiny.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output tensors info\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# Function to preprocess the input image\n",
    "def preprocess_image(image_path):\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image = image.resize((64, 64))\n",
    "    image = np.asarray(image).astype(np.float32) / 255.0\n",
    "\n",
    "    # Normalize using the same mean and std used during training\n",
    "    mean = np.array([0.485, 0.456, 0.406], dtype=np.float32)\n",
    "    std = np.array([0.229, 0.224, 0.225], dtype=np.float32)\n",
    "    image = (image - mean) / std\n",
    "\n",
    "    # Convert HWC -> CHW\n",
    "    image = image.transpose(2, 0, 1)\n",
    "\n",
    "    # Add batch dimension\n",
    "    image = np.expand_dims(image, axis=0).astype(np.float32)\n",
    "    return image\n",
    "\n",
    "\n",
    "# Load and preprocess input imag\n",
    "image_path = f\"./fake/id2_id4_0007_frame_23.png\"\n",
    "input_data = preprocess_image(image_path)\n",
    "\n",
    "# Ensure input type matches the model's expected type\n",
    "input_index = input_details[0]['index']\n",
    "interpreter.set_tensor(input_index, input_data)\n",
    "\n",
    "# Run inference\n",
    "interpreter.invoke()\n",
    "\n",
    "# Get the output\n",
    "output_index = output_details[0]['index']\n",
    "output_data = interpreter.get_tensor(output_index)\n",
    "\n",
    "# Get predicted class\n",
    "predicted_class = np.argmax(output_data)\n",
    "print(f\"Predicted class: {predicted_class}, Scores: {output_data}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.13.2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
